import streamlit as st
from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification
import torch

# –ó–∞–≥–æ–ª–æ–≤–æ–∫ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
st.title("üìû –ê–≥–µ–Ω—Ç –æ—Ü–µ–Ω–∫–∏ –∑–≤–æ–Ω–∫–æ–≤")
st.write("–ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∫—É —Ä–∞–∑–≥–æ–≤–æ—Ä–∞, –∏ –ò–ò –æ—Ü–µ–Ω–∏—Ç –µ–≥–æ —Ç–æ–Ω –∏ –¥–∞—Å—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏.")


# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ (–∫—ç—à–∏—Ä—É–µ–º, —á—Ç–æ–±—ã –Ω–µ –≥—Ä—É–∑–∏—Ç—å –∫–∞–∂–¥—ã–π —Ä–∞–∑)
@st.cache(allow_output_mutation=True)
def load_analysis_model():
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º pipeline –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏
    sentiment_pipeline = pipeline(
        "sentiment-analysis",
        model="cardiffnlp/twitter-roberta-base-sentiment-latest",
        tokenizer="cardiffnlp/twitter-roberta-base-sentiment-latest"
    )
    return sentiment_pipeline


@st.cache(allow_output_mutation=True)
def load_generation_model():
    # –î–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –Ω–∞–º –Ω—É–∂–Ω—ã –æ—Ç–¥–µ–ª—å–Ω–æ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä –∏ –º–æ–¥–µ–ª—å
    model_name = "cardiffnlp/twitter-roberta-base-sentiment-latest"
    tokenizer = AutoTokenizer.from_pretrained(model_name)
    model = AutoModelForSequenceClassification.from_pretrained(model_name)
    return tokenizer, model


# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π —Å –ø–æ–º–æ—â—å—é –ø—Ä–æ–º–ø—Ç–∞
def generate_recommendation(sentiment_label, text, tokenizer, model):
    # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ–º–ø—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–≥–æ —Ç–æ–Ω–∞ —Ä–∞–∑–≥–æ–≤–æ—Ä–∞
    prompt = f"""
    Analyze the following customer service conversation transcript: "{text[:500]}"
    The overall tone was {sentiment_label}.
    Provide one or two short, actionable recommendations in Russian for the agent to improve the conversation.
    Recommendations:
    """
    # –ö–æ–¥–∏—Ä—É–µ–º –ø—Ä–æ–º–ø—Ç –∏ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç
    inputs = tokenizer(prompt, return_tensors="pt", truncation=True, max_length=512)
    with torch.no_grad():
        outputs = model(**inputs)

    # –ó–¥–µ—Å—å –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –ª–æ–≥–∏–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞, –Ω–æ —Ç.–∫. –º–æ–¥–µ–ª—å –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–æ–Ω–Ω–∞—è, –º—ã –∏–º–∏—Ç–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç
    # –í —Ä–µ–∞–ª—å–Ω–æ—Å—Ç–∏ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –Ω—É–∂–Ω–∞ –º–æ–¥–µ–ª—å —Ç–∏–ø–∞ T5 –∏–ª–∏ GPT
    recommendations = {
        "negative": "1. –ü—Ä–æ—è–≤–∏—Ç–µ –±–æ–ª—å—à–µ —ç–º–ø–∞—Ç–∏–∏: '–ü–æ–Ω–∏–º–∞—é –≤–∞—à–µ —Ä–∞–∑–æ—á–∞—Ä–æ–≤–∞–Ω–∏–µ, –¥–∞–≤–∞–π—Ç–µ –Ω–∞–π–¥–µ–º —Ä–µ—à–µ–Ω–∏–µ –≤–º–µ—Å—Ç–µ.'\n2. –ò–∑–±–µ–≥–∞–π—Ç–µ —à–∞–±–ª–æ–Ω–Ω—ã—Ö —Ñ—Ä–∞–∑, –ø—Ä–µ–¥–ª–∞–≥–∞–π—Ç–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Å–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏.",
        "neutral": "1. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø—Ä–æ—è–≤–∏—Ç—å –±–æ–ª—å—à–µ —ç–Ω—Ç—É–∑–∏–∞–∑–º–∞, —á—Ç–æ–±—ã —Ä–∞—Å–ø–æ–ª–æ–∂–∏—Ç—å –∫ —Å–µ–±–µ –∫–ª–∏–µ–Ω—Ç–∞.\n2. –ó–∞–¥–∞–≤–∞–π—Ç–µ —É—Ç–æ—á–Ω—è—é—â–∏–µ –≤–æ–ø—Ä–æ—Å—ã, —á—Ç–æ–±—ã –ª—É—á—à–µ –ø–æ–Ω—è—Ç—å –ø–æ—Ç—Ä–µ–±–Ω–æ—Å—Ç–∏.",
        "positive": "1. –û—Ç–ª–∏—á–Ω–∞—è —Ä–∞–±–æ—Ç–∞! –ü—Ä–æ–¥–æ–ª–∂–∞–π—Ç–µ –≤ —Ç–æ–º –∂–µ –¥—É—Ö–µ.\n2. –ú–æ–∂–µ—Ç–µ –ø—Ä–µ–¥–ª–æ–∂–∏—Ç—å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—É—é –ø–æ–º–æ—â—å –∏–ª–∏ –ø—Ä–æ–¥—É–∫—Ç, —Ç–∞–∫ –∫–∞–∫ –∫–ª–∏–µ–Ω—Ç –Ω–∞—Å—Ç—Ä–æ–µ–Ω –ø–æ–∑–∏—Ç–∏–≤–Ω–æ."
    }
    return recommendations.get(sentiment_label, "–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã.")


# –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª–∏
analyzer = load_analysis_model()
tokenizer, model = load_generation_model()

# –ü–æ–ª–µ –¥–ª—è –≤–≤–æ–¥–∞ —Ç–µ–∫—Å—Ç–∞
call_transcript = st.text_area(
    "–í—Å—Ç–∞–≤—å—Ç–µ —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∫—É —Ä–∞–∑–≥–æ–≤–æ—Ä–∞:",
    height=200,
    placeholder="–í–≤–µ–¥–∏—Ç–µ —Ç–µ–∫—Å—Ç —Ä–∞–∑–≥–æ–≤–æ—Ä–∞ –∑–¥–µ—Å—å..."
)

if st.button("–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ä–∞–∑–≥–æ–≤–æ—Ä") and call_transcript:
    with st.spinner('–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ç–æ–Ω —Ä–∞–∑–≥–æ–≤–æ—Ä–∞...'):
        # –ê–Ω–∞–ª–∏–∑ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏
        sentiment_result = analyzer(call_transcript[:512])  # –û–±—Ä–µ–∑–∞–µ–º —Ç–µ–∫—Å—Ç –¥–ª—è –º–æ–¥–µ–ª–∏
        sentiment_label = sentiment_result[0]['label']
        sentiment_score = sentiment_result[0]['score']

        # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –æ—Ü–µ–Ω–∫–∏ —Ç–æ–Ω–∞
        if sentiment_label == "positive":
            st.success(f"–¢–æ–Ω —Ä–∞–∑–≥–æ–≤–æ—Ä–∞: –ü–æ–∑–∏—Ç–∏–≤–Ω—ã–π ({sentiment_score:.2f})")
        elif sentiment_label == "negative":
            st.error(f"–¢–æ–Ω —Ä–∞–∑–≥–æ–≤–æ—Ä–∞: –ù–µ–≥–∞—Ç–∏–≤–Ω—ã–π ({sentiment_score:.2f})")
        else:
            st.info(f"–¢–æ–Ω —Ä–∞–∑–≥–æ–≤–æ—Ä–∞: –ù–µ–π—Ç—Ä–∞–ª—å–Ω—ã–π ({sentiment_score:.2f})")

    with st.spinner('–ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏...'):
        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π
        recommendations = generate_recommendation(sentiment_label, call_transcript, tokenizer, model)

        st.subheader("–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —É–ª—É—á—à–µ–Ω–∏—é:")
        st.write(recommendations)

else:
    st.warning("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤–≤–µ–¥–∏—Ç–µ —Ç–µ–∫—Å—Ç —Ä–∞–∑–≥–æ–≤–æ—Ä–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞.")